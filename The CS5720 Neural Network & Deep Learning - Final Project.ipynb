{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffe7a8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9e9dfd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2316b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the FruitNet dataset using TensorFlow's ImageDataGenerator class.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "#         '/path/to/dataset/'\n",
    "         'C:\\\\Users\\\\n\\\\Downloads\\\\FruitNetDataset',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199ccf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the dataset by dividing the images into three categories: good, bad, and mixed.\n",
    "good_fruits = [image for image in train_generator if np.argmax(image[1]) == 0]\n",
    "bad_fruits = [image for image in train_generator if np.argmax(image[1]) == 1]\n",
    "mixed_fruits = [image for image in train_generator if np.argmax(image[1]) == 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488f7b1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define the generator and discriminator models for the Cycle-GAN algorithm. \n",
    "# The generator model  have two components: an encoder and a decoder. The discriminator model is a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04445c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    " # Define the generator models\n",
    "# generator_G = keras.Sequential([...])\n",
    "# generator_F = keras.Sequential([...])\n",
    "\n",
    "from tensorflow import keras\n",
    "def build_generator():\n",
    "    # Generator G: Converts bad quality images to good quality images\n",
    "    generator_G = keras.Sequential([\n",
    "        keras.layers.Input(shape=(256, 256, 3)),\n",
    "        # Downsampling\n",
    "        keras.layers.Conv2D(64, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(128, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        # Residual blocks\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation=None),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Add(),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation=None),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Add(),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation=None),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Add(),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Conv2DTranspose(128, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
    "    ], name='generator_G')\n",
    "\n",
    "    # Generator F: Converts good quality images to bad quality images\n",
    "    generator_F = keras.Sequential([\n",
    "        keras.layers.Input(shape=(256, 256, 3)),\n",
    "        # Downsampling\n",
    "        keras.layers.Conv2D(64, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(128, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 4, strides=2, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        # Residual blocks\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation=None),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Add(),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation=None),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Add(),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(256, 3, padding='same', activation=None),\n",
    "        keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\", kernel_initializer=initializer, use_bias=False),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d904364",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the generator models\n",
    "generator_G = keras.Sequential([\n",
    "    # Encoder\n",
    "    keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=img_shape),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    # Transformer\n",
    "    keras.layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    # Decoder\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\")\n",
    "])\n",
    "\n",
    "generator_F = keras.Sequential([\n",
    "    # Encoder\n",
    "    keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=img_shape),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    # Transformer\n",
    "    keras.layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "    # Decoder\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51583768",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the discriminator models\n",
    "    # discriminator_X = keras.Sequential([...])\n",
    "   # discriminator_Y = keras.Sequential([...])\n",
    "\n",
    "discriminator_X = keras.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=img_shape),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(1, kernel_size=4, strides=1, padding=\"same\")\n",
    "])\n",
    "\n",
    "discriminator_Y = keras.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=img_shape),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "    keras.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(1, kernel_size=4, strides=1, padding=\"same\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481e7cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss functions for the Cycle-GAN algorithm. \n",
    "# The adversarial loss, cycle consistency loss, and identity loss should all be used.\n",
    "# Define the adversarial loss function\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "    return keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "\n",
    "# Define the cycle consistency loss function\n",
    "def cycle_consistency_loss(y_true, y_pred):\n",
    "    return keras.losses.MeanAbsoluteError()(y_true, y_pred)\n",
    "\n",
    "# Define the identity loss function\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return keras.losses.MeanAbsoluteError()(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a4dfb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train the Cycle-GAN algorithm using the preprocessed dataset.\n",
    "# During training, the mean absolute and mean squared errors can be used as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69980655",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the optimizers for the generator and discriminator models\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Compile the generator and discriminator models\n",
    "generator_G.compile(loss=[adversarial_loss, cycle_consistency_loss, identity_loss], optimizer=optimizer)\n",
    "generator_F.compile(loss=[adversarial_loss, cycle_consistency_loss, identity_loss], optimizer=optimizer)\n",
    "discriminator_X.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "discriminator_Y.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# Train the Cycle-GAN algorithm\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_generator:\n",
    "        # Get the batch of images and labels\n",
    "        real_images_X, real_images_Y = batch\n",
    "        \n",
    "        # Train the generator models\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Generate fake images\n",
    "            fake_images_Y = generator_G(real_images_X, training=True)\n",
    "            fake_images_X = generator_F(real_images_Y, training=True)\n",
    "            \n",
    "            # Reconstruct original images\n",
    "            reconstructed_images_X = generator_F(fake_images_Y, training=True)\n",
    "            reconstructed_images_Y = generator_G(fake_images_X, training=True)\n",
    "            \n",
    "            # Calculate the adversarial, cycle consistency, and identity losses\n",
    "            adversarial_loss_X = adversarial_loss(tf.ones_like(discriminator_X(real_images_X)), discriminator_X(real_images_X))\n",
    "            adversarial_loss_Y = adversarial_loss(tf.ones_like(discriminator_Y(real_images_Y)), discriminator_Y(real_images_Y))\n",
    "            cycle_consistency_loss_X = cycle_consistency_loss(real_images_X, reconstructed_images_X)\n",
    "            cycle_consistency_loss_Y = cycle_consistency_loss(real_images_Y, reconstructed_images_Y)\n",
    "            identity_loss_X = identity_loss(real_images_X, generator_F(real_images_X))\n",
    "            identity_loss_Y = identity_loss(real_images_Y, generator_G(real_images_Y))\n",
    "            \n",
    "            # Calculate the total generator losses\n",
    "            total_loss_G = (\n",
    "                adversarial_loss_X \n",
    "                + adversarial_loss_Y \n",
    "                + cycle_consistency_loss_X \n",
    "                + cycle_consistency_loss_Y \n",
    "                + identity_loss_X \n",
    "                + identity_loss_Y\n",
    "            )\n",
    "        \n",
    "        # Calculate the gradients for the generator models\n",
    "        gradients_G = tape.gradient(total_loss_G, generator_G.trainable_variables + generator_F.trainable_variables)\n",
    "        \n",
    "        # Apply the gradients to the generator models\n",
    "        optimizer.apply_gradients(zip(gradients_G, generator_G.trainable_variables + generator_F.trainable_variables))\n",
    "        \n",
    "        # Train the discriminator models\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Calculate the discriminator losses for real and fake images\n",
    "            real_loss_X = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.ones_like(discriminator_X(real_images_X)), discriminator_X(real_images_X)))\n",
    "            fake_loss_X = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.zeros_like(discriminator_X(fake_images_X)), discriminator_X(fake_images_X)))\n",
    "            real_loss_Y = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.ones_like(discriminator_Y(real_images_Y)), discriminator_Y(real_images_Y)))\n",
    "            fake_loss_Y = tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.zeros_like(discriminator_Y(fake_images_Y)), discriminator_Y(fake_images_Y)))\n",
    "            \n",
    "  \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54ac65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "          # Calculate the total discriminator losses\n",
    "# Define the lists to store the discriminator losses\n",
    "disc_loss_X_real = []\n",
    "disc_loss_X_fake = []\n",
    "disc_loss_Y_real = []\n",
    "disc_loss_Y_fake = []\n",
    "\n",
    "# Train the discriminators\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    \n",
    "    \n",
    "    # Train the discriminators\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    # Get the real images\n",
    "    real_X, real_Y = batch[0], batch[1]\n",
    "    # Generate fake images\n",
    "    fake_X = generator_F(real_Y)\n",
    "    fake_Y = generator_G(real_X)\n",
    "    # Train the discriminator for real and fake images\n",
    "    discriminator_X.trainable = True\n",
    "    discriminator_Y.trainable = True\n",
    "    d_X_loss_real = discriminator_X.train_on_batch(real_X, np.ones((batch_size, 1)))\n",
    "    d_X_loss_fake = discriminator_X.train_on_batch(fake_X, np.zeros((batch_size, 1)))\n",
    "    d_X_loss = 0.5 * np.add(d_X_loss_real, d_X_loss_fake)\n",
    "    d_Y_loss_real = discriminator_Y.train_on_batch(real_Y, np.ones((batch_size, 1)))\n",
    "    d_Y_loss_fake = discriminator_Y.train_on_batch(fake_Y, np.zeros((batch_size, 1)))\n",
    "    d_Y_loss = 0.5 * np.add(d_Y_loss_real, d_Y_loss_fake)\n",
    "    # Update discriminator weights\n",
    "    discriminator_X.trainable = False\n",
    "    discriminator_Y.trainable = False\n",
    "    # Train the generator\n",
    "    g_loss = combined.train_on_batch([real_X, real_Y], [np.ones((batch_size, 1)), real_X, real_Y, real_X, real_Y])\n",
    "    # Print the progress\n",
    "    if i % print_interval == 0:\n",
    "        print(\"Epoch {} Batch {} Discriminator_X_Loss {:.4f} Discriminator_Y_Loss {:.4f} Generator_Loss {:.4f}\".format(\n",
    "            epoch+1, i+1, d_X_loss, d_Y_loss, g_loss[0]))\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cdabd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Calculate the discriminator losses for this batch\n",
    "disc_loss_X_real.append(d_loss_X_real)\n",
    "disc_loss_X_fake.append(d_loss_X_fake)\n",
    "disc_loss_Y_real.append(d_loss_Y_real)\n",
    "disc_loss_Y_fake.append(d_loss_Y_fake)\n",
    "\n",
    "# Calculate the mean discriminator losses for this epoch\n",
    "mean_disc_loss_X_real = np.mean(disc_loss_X_real)\n",
    "mean_disc_loss_X_fake = np.mean(disc_loss_X_fake)\n",
    "mean_disc_loss_Y_real = np.mean(disc_loss_Y_real)\n",
    "mean_disc_loss_Y_fake = np.mean(disc_loss_Y_fake)\n",
    "total_disc_loss = mean_disc_loss_X_real + mean_disc_loss_X_fake + mean_disc_loss_Y_real + mean_disc_loss_Y_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b6d82",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  Evaluate the trained Cycle-GAN algorithm using mean absolute and mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e46cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained Cycle-GAN model\n",
    "cycle_gan = tf.keras.models.load_model('cycle_gan_model.h5')\n",
    "\n",
    "# Load the test dataset\n",
    "test_data_dir = 'C:\\\\Users\\\\n\\\\Downloads\\\\FruitNetDataset'\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Generate fake images using the Cycle-GAN model\n",
    "fake_images = cycle_gan.predict(test_generator)\n",
    "\n",
    "# Calculate mean absolute error and mean squared error\n",
    "mae = np.mean(np.abs(test_generator - fake_images))\n",
    "mse = np.mean(np.square(test_generator - fake_images))\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261770c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}